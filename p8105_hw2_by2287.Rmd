---
title: "p8105_hw2_by2287"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(readr)
library(readxl)
```


## Problem 1 

Read in & clean the trash-wheel dataset
```{r read in & clean in trash_wheel data}
trash_wheel = read_xlsx(
                  path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                  sheet = 1, 
                  skip = 1,
                  range = cell_cols("A:N")) %>% 
	        janitor::clean_names() %>% 
          filter(dumpster != "NA") %>% 
            mutate(
              sports_balls = round(sports_balls),
              sports_balls = as.integer(sports_balls)
            ) 
```

The dataset trash_wheel consists of `r nrow(trash_wheel)` rows and `r ncol(trash_wheel)` columns. It includes 
columns that capture information on things like the total amount of `r trash_wheel %>% select(plastic_bottles, grocery_bags, sports_balls) %>% names()` 
collected by Mr Trash Wheel, by year. For instance, the median sport balls collected by My Trash Wheel in 2017 was `r trash_wheel %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`.


Read in & clean the precipitation data for 2017 & 2018
```{r read in 2017 & 2018 precipitation data}
precip_2017 = read_xlsx(
                  path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                  sheet = "2017 Precipitation",
                  skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)


precip_2018 = read_xlsx(
                  path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                  sheet = "2018 Precipitation", 
                  skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
   relocate(year)
                  

precip_df = bind_rows(precip_2017, precip_2018)


precip_df = precip_df %>% 
      mutate(month = month.name[month])
```

The data set precip_df, which contains the combined information of the 2017 & 2018 precipitation data, 
consists of `r nrow(precip_df)` rows and `r ncol(precip_df)` columns. It contains information, on the 
year, month, and the corresponding total precipitation. In the year 2017, the median precipitation was 
`r precip_df %>% filter(year == 2017) %>% pull(total) %>% median() %>% round(2)` whereas 2018 saw a median precipitation of
`r precip_df %>% filter(year == 2018) %>% pull(total) %>% median() %>% round(2)`.

## Problem 2
Read and clean the nyc_transit data
```{r read nyc_transit data}
nyc_transit = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
              janitor::clean_names() %>% 
              select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
              mutate(
                entry = ifelse(entry == "YES", 1, 0)
                ) 
```

The data set nyc_transit is cleaner version of the NYC_Transit_Subway_Entrance_And_Exit_Data. It consists of `r nrow(nyc_transit)` rows and `r ncol(nyc_transit)` columns. It contains information on different subway stations in New York City, and has, in it, variables such as: `r nyc_transit %>% select(line:station_longitude, entrance_type) %>% names()`. The cleaning steps includes, converting the variable names to snake_case, selecting only relevant variables, and re-coding the `entry` variable from YES/NO to 1/0. In addition to these, it also contains information on what routes they take, and whether or not the stations are ADA compliant. These data are tidy. 


From the nyc_transit data set, we can tell that there are `r nyc_transit %>% distinct(line,station_name) %>% count()` distinct stations. 
Of those distinct stations, `r nyc_transit %>% filter(ada == TRUE) %>% distinct(line, station_name) %>% count()` are ADA compliant. 


#What proportion of station entrances / exits without vending allow entrance?
The proportion of station entrances / exits without vending that allow entrance is:
`r (nyc_transit %>% filter(entry == 1 & vending == "NO") %>% count() / nyc_transit %>% filter(vending == "NO") %>% count())`

########Remaining questions:
Reformat data so that route number and route name are distinct variables. 
How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

Reformating data
```{r reformat data}

transit_pivot = nyc_transit %>% 
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)
         ) %>% 
 pivot_longer(c("route1":"route11"), names_to = "route_name", values_to = "route_number", values_drop_na = T)
  
  
```

## Problem 3
```{r read in data sets and tidy up}
pols = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(
    month = as.integer(month),
    month = month.name[month], 
    president = ifelse(prez_dem == 1, "dem", "gop")) %>% 
  select(-c(prez_dem, prez_gop, day))
    
  
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, into = c("month", "day", "year")) %>% 
  mutate(
    month = as.integer(month),
    month = month.name[month]) %>% 
   select(-c(day)) %>% 
  relocate(year)

month_df = 
	tibble(
		month = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"),
		month_name = month.name
	)

unemployment = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(c(Jan:Dec), names_to = "month") %>% 
  rename(unemployment_rate = value) %>% 
  janitor::clean_names() %>% 
  left_join(month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>% 
  relocate(month) %>% 
  relocate(year) %>% 
  mutate(
    year = as.character(year)
  )

```


Merging the 3 data sets
```{r creating master data set}
snp_pols = left_join(pols, snp, by = c("year", "month"))

snp_pols_unemp = left_join(snp_pols, unemployment, by = c("year", "month"))
```

The dataset `snp_pols_unemp` is a merged data frame made up of 3 datasets (renamed from the original to make it shorter): `pols`, `snp`, & `unemployment`. 

The `pols` data set contained information on the number of politicians who were either democratic or republicans, at any given time. 
This dataset had `r nrow(pols)` observations and `r ncol(pols)` variables. 

The `snp` dataset contained `r nrow(snp)` observations and `r ncol(snp)` variables on the SNP index at any given time (a proxy measure of the economy.) 

Finally, the `unemployment` dataset contained `r nrow(unemployment)` observations and `r ncol(unemployment)` variables that described the unemployment rate at any given time. 

After tidying and then merging these data sets, the resulting "snp_pols_unemp" contains `r nrow(snp_pols_unemp)` observations and `r ncol(snp_pols_unemp)` variables. 
This data contains information within this time period: `r snp_pols_unemp %>% pull(year) %>% range()`; and it contains interesting variables such as: 
`r snp_pols_unemp %>% select(president, unemployment_rate) %>% names()`



 


