p8105\_hw2\_by2287
================

## Problem 1

Read in & clean the trash-wheel dataset

``` r
trash_wheel = read_xlsx(
                  path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                  sheet = 1, 
                  skip = 1,
                  range = cell_cols("A:N")) %>% 
            janitor::clean_names() %>% 
          filter(dumpster != "NA") %>% 
            mutate(
              sports_balls = round(sports_balls),
              sports_balls = as.integer(sports_balls)
            ) 
```

The dataset trash\_wheel consists of 344 rows and 14 columns. It
includes columns that capture information on things like the total
amount of plastic\_bottles, grocery\_bags, sports\_balls collected by Mr
Trash Wheel, by year. For instance, the median sport balls collected by
My Trash Wheel in 2017 was 8.

Read in & clean the precipitation data for 2017 & 2018

``` r
precip_2017 = read_xlsx(
                  path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                  sheet = "2017 Precipitation",
                  skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)


precip_2018 = read_xlsx(
                  path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
                  sheet = "2018 Precipitation", 
                  skip = 1) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
   relocate(year)
                  

precip_df = bind_rows(precip_2017, precip_2018)


precip_df = precip_df %>% 
      mutate(month = month.name[month])
```

The data set precip\_df, which contains the combined information of the
2017 & 2018 precipitation data, consists of 24 rows and 3 columns. It
contains information, on the year, month, and the corresponding total
precipitation. In the year 2017, the median precipitation was 2.14
whereas 2018 saw a median precipitation of 5.46.

## Problem 2

Read and clean the nyc\_transit data

``` r
nyc_transit = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
              janitor::clean_names() %>% 
              select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>% 
              mutate(
                entry = ifelse(entry == "YES", 1, 0)
                ) 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The data set nyc\_transit is cleaner version of the
NYC\_Transit\_Subway\_Entrance\_And\_Exit\_Data. It consists of 1868
rows and 19 columns. It contains information on different subway
stations in New York City, and has, in it, variables such as: line,
station\_name, station\_latitude, station\_longitude, entrance\_type.
The cleaning steps includes, converting the variable names to
snake\_case, selecting only relevant variables, and re-coding the
`entry` variable from YES/NO to 1/0. In addition to these, it also
contains information on what routes they take, and whether or not the
stations are ADA compliant. These data are tidy.

From the nyc\_transit data set, we can tell that there are 465 distinct
stations. Of those distinct stations, 84 are ADA compliant.

\#What proportion of station entrances / exits without vending allow
entrance? The proportion of station entrances / exits without vending
that allow entrance is: 0.0967742

\#\#\#\#\#\#\#\#Remaining questions: Reformat data so that route number
and route name are distinct variables. How many distinct stations serve
the A train? Of the stations that serve the A train, how many are ADA
compliant?

## Problem 3

``` r
pols = read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(
    month = as.integer(month),
    month = month.name[month], 
    president = ifelse(prez_dem == 1, "dem", "gop")) %>% 
  select(-c(prez_dem, prez_gop, day))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, into = c("month", "day", "year")) %>% 
  mutate(
    month = as.integer(month),
    month = month.name[month]) %>% 
   select(-c(day)) %>% 
  relocate(year)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
month_df = 
    tibble(
        month = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"),
        month_name = month.name
    )

unemployment = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(c(Jan:Dec), names_to = "month") %>% 
  rename(unemployment_rate = value) %>% 
  janitor::clean_names() %>% 
  left_join(month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>% 
  relocate(month) %>% 
  relocate(year) %>% 
  mutate(
    year = as.character(year)
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Merging the 3 data sets

``` r
snp_pols = left_join(pols, snp, by = c("year", "month"))

snp_pols_unemp = left_join(snp_pols, unemployment, by = c("year", "month"))
```

The dataset `snp_pols_unemp` is a merged data frame made up of 3
datasets (renamed from the original to make it shorter): `pols`, `snp`,
& `unemployment`.

The `pols` data set contained information on the number of politicians
who were either democratic or republicans, at any given time. This
dataset had 822 observations and 9 variables.

The `snp` dataset contained 787 observations and 3 variables on the SNP
index at any given time (a proxy measure of the economy.)

Finally, the `unemployment` dataset contained 816 observations and 3
variables that described the unemployment rate at any given time.

After tidying and then merging these data sets, the resulting
“snp\_pols\_unemp” contains 822 observations and 11 variables. This
data contains information within this time period: 1947, 2015; and it
contains interesting variables such as: president, unemployment\_rate
